{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEnsemble method means applying different decision trees together.\\nIdea to apply different trees together is to improve the model and makes it better model.\\nThese decision trees are slow learners and together they creates model which is fast learner.\\n\\nWhat Ensemble Method Solves\\n===========================\\nIt solves the problem of overfitting.\\n\\nWhat is overfitting\\n===================\\nOverfitting means when testing accuracy is less than training accuracy.\\n\\nDifferent Ensemble Methods\\n==========================\\n1.) Random forest\\n2.) Bagging\\n3.) Boosting\\n4.) Stacking\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Ensemble method means applying different decision trees together.\n",
    "Idea to apply different trees together is to improve the model and makes it better model.\n",
    "These decision trees are slow learners and together they creates model which is fast learner.\n",
    "\n",
    "What Ensemble Method Solves\n",
    "===========================\n",
    "It solves the problem of overfitting.\n",
    "\n",
    "What is overfitting\n",
    "===================\n",
    "Overfitting means when testing accuracy is less than training accuracy.\n",
    "\n",
    "Different Ensemble Methods\n",
    "==========================\n",
    "1.) Random forest\n",
    "2.) Bagging\n",
    "3.) Boosting\n",
    "4.) Stacking\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nHow Random Forest works\\n=======================\\nTechnique Used: Bootstrap with replacement (Statistical Technique for randomnly selecting data points)\\nAlgorithm Used: Decision trees\\n\\nHow it works\\n============\\nFor each set of samples which is taken out with replacement that is those samples can be used again\\nFor each set of samples number of features taken out is sqrt(total features or variables)\\n\\nAdvantage of Random Forest\\n==========================\\nIt solves overfitting and missing value problem.\\n\\nCross Validation Techniques\\n===========================\\nDifferent cross validation techniques are used such as below\\n a.) Leave one out\\n b.) Leave p pout\\n c.) K-fold\\n d.) Repeated random sub sampling validation  \\n\\nWe are implementing K-fold for random forest\\n============================================\\n1.) During K fold we have value of k which denotes number of groups that a given data is to be split\\n2.) Accuracy or performance paramters is calculated 10 times as K is 10\\n3.) During each calculation one group is chosen as testing and rest others as training dataset, keeping in mind that\\ngroup once chosen for testing dataset is not repeated in the next step\\n\\nAverage of the accuracy during these 10 iterations is chosen as final accuracy\\n\\nSome Key points with respect to random forest method\\n=====================================================\\nFor classification: Majority of vote from decision tree is chosen as answer\\nFor Regression : Average of output from each decision tree is chosen as answer\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "How Random Forest works\n",
    "=======================\n",
    "Technique Used: Bootstrap with replacement (Statistical Technique for randomnly selecting data points)\n",
    "Algorithm Used: Decision trees\n",
    "\n",
    "How it works\n",
    "============\n",
    "For each set of samples which is taken out with replacement that is those samples can be used again\n",
    "For each set of samples number of features taken out is sqrt(total features or variables)\n",
    "\n",
    "Advantage of Random Forest\n",
    "==========================\n",
    "It solves overfitting and missing value problem.\n",
    "\n",
    "Cross Validation Techniques\n",
    "===========================\n",
    "Different cross validation techniques are used such as below\n",
    " a.) Leave one out\n",
    " b.) Leave p pout\n",
    " c.) K-fold\n",
    " d.) Repeated random sub sampling validation  \n",
    "\n",
    "We are implementing K-fold for random forest\n",
    "============================================\n",
    "1.) During K fold we have value of k which denotes number of groups that a given data is to be split\n",
    "2.) Accuracy or performance paramters is calculated 10 times as K is 10\n",
    "3.) During each calculation one group is chosen as testing and rest others as training dataset, keeping in mind that\n",
    "group once chosen for testing dataset is not repeated in the next step\n",
    "\n",
    "Average of the accuracy during these 10 iterations is chosen as final accuracy\n",
    "\n",
    "Some Key points with respect to random forest method\n",
    "=====================================================\n",
    "For classification: Majority of vote from decision tree is chosen as answer\n",
    "For Regression : Average of output from each decision tree is chosen as answer\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Random Forest on Diabetes Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries to read the dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_read = pd.read_csv(\n",
    "           'pima-indians-diabetes.csv', \n",
    "            names = columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>test</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preg  plas  pres  skin  test  mass   pedi  age  class_name\n",
       "0     6   148    72    35     0  33.6  0.627   50           1\n",
       "1     1    85    66    29     0  26.6  0.351   31           0\n",
       "2     8   183    64     0     0  23.3  0.672   32           1\n",
       "3     1    89    66    23    94  28.1  0.167   21           0\n",
       "4     0   137    40    35   168  43.1  2.288   33           1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_read.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the dataset into data and target\n",
    "# from data I mean all the columns except last one\n",
    "# from the target I mean only the target column\n",
    "X = dataframe_read.iloc[:, 0:dataframe_read.shape[1]-1]\n",
    "y = dataframe_read.iloc[:, dataframe_read.shape[1]-1]\n",
    "\n",
    "# getting the features from the data\n",
    "features =  X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the model\n",
    "model = RandomForestClassifier(\n",
    "                    max_depth=2, \n",
    "                    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For kfold we donot need to split the dataset into data and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'i'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-3905a6c53fd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         print(\"Accuracy for the fold no. {i} on the test set is {}:\".format(\n\u001b[1;32m     13\u001b[0m                               \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                               accuracy_score(y_test, model.predict(X_test)))\n\u001b[0m\u001b[1;32m     15\u001b[0m         )\n\u001b[1;32m     16\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'i'"
     ]
    }
   ],
   "source": [
    "# suppose we are working with three k fold\n",
    "# https://github.com/vaasha/Machine-leaning-in-examples/blob/master/sklearn/cross-validation/Cross%20Validation.ipynb\n",
    "kf3 = KFold(n_splits=3, shuffle=False)\n",
    "\n",
    "i = 1\n",
    "for train_index, test_index in kf3.split(dataframe_read):\n",
    "        X_train = dataframe_read.iloc[train_index].loc[:, features]\n",
    "        X_test = dataframe_read.iloc[test_index].loc[:, features]\n",
    "        y_train = dataframe_read.iloc[train_index].loc[:,'class_name']\n",
    "        y_test = dataframe_read.iloc[test_index].loc[:, 'class_name']\n",
    "        model.fit(X_train, y_train)\n",
    "        print(\"Accuracy for the fold no. {i} on the test set is {}:\".format(\n",
    "                              i, \n",
    "                              accuracy_score(y_test, model.predict(X_test)))\n",
    "        )\n",
    "        i +=1\n",
    "                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/vaasha/Machine-leaning-in-examples/blob/master/sklearn/cross-validation/Cross%20Validation.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
